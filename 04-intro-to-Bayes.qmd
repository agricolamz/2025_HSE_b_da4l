---
editor_options: 
  chunk_output_type: console
---
```{r setup04}
#| include: false

knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = "")
options(scipen=999)
library(tidyverse)
theme_set(theme_bw())
library(latex2exp)
```

# Байесовский статистический вывод

## Нотация

В байесовском подходе статистический вывод описывается формулой Байеса

$$P(θ|Data) = \frac{P(Data|θ)\times P(θ)}{P(Data)}$$

* $P(θ|Data)$ --- апостериорная вероятность (posterior)
* $P(Data|θ)$ --- функция правдоподобия (likelihood)
* $P(θ)$ ---  априорная вероятность (prior)
* $P(Data)$ --- нормализующий делитель

В литературе можно еще встретить такую запись:

$$P(θ|Data) \propto P(Data|θ)\times P(θ)$$

На прошлых занятиях мы говорили, что [функция правдоподобия не обязана интегрироваться до 1](https://stats.stackexchange.com/a/31241/225843), тогда почему, назвав часть формулы Байеса $P(Data|θ)$ функцией правдоподобия, мы оставляем нотацию, будто это функция вероятностей? Потому что это условная вероятность, [она не обязана интегрироваться до 1](https://stats.stackexchange.com/q/448852/225843).

## Категориальный пример

Для примера я взял датасет, который содержит спамерские и обычные смс-сообщения, выложенный UCI Machine Learning [на kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset) и при помощи пакета `udpipe` токенизировал и определил часть речи:

```{r, fig.width=9, fig.height=7}
#| fig-width: 9
#| fig-height: 7

sms_pos <- read_csv("https://raw.githubusercontent.com/agricolamz/2024_HSE_b_da4l/main/data/spam_sms_pos.csv")
glimpse(sms_pos)

sms_pos |> 
  group_by(type) |> 
  mutate(ratio = n/sum(n),
         upos = fct_reorder(upos, n, mean, .desc = TRUE)) |>
  ggplot(aes(type, ratio))+
  geom_col()+
  geom_label(aes(label = round(ratio, 3)), position = position_stack(vjust = 0.5))+
  facet_wrap(~upos, scales = "free_y")
```

Давайте полученные доли считать нашей моделью: сумма всех чисел внутри каждого типа (`ham`/`spam`) дает в сумме 1. Мы получили новое сообщение: 

> Call FREEPHONE 0800 542 0825 now! 

Модель `udpipe` разобрала его следующим образом: 

> VERB NUM NUM NUM NUM ADV PUNCT 

Понятно, что это -- спам, но мы попытаемся применить байесовский статистический вывод, чтобы определить тип сообщения. Предположим, что машина считает обе гипотезы равновероятными, т. е. ее априорное распределение гипотез равно 0.5 каждая. На минуту представим, что машина анализирует текст пословно. Первое слово типа `VERB`. Функции правдоподобия равны 0.135 и 0.096 для сообщений типа `ham` и `spam` соответственно. Применим байесовский апдейт:

```{r}
tibble(model = c("ham", "spam"),
       prior = 0.5,
       likelihood = c(0.135, 0.096),
       product = prior*likelihood,
       posterior = product/sum(product))
```

Вот мы и сделали байесовский апдейт. Теперь апостериорное распределение, которое мы получили на предыдущем шаге, мы можем использовать в новом апдейте. Следующее слово в сообщении типа `NUM`.

```{r}
tibble(model = c("ham", "spam"),
       prior_2 = c(0.584, 0.416),
       likelihood_2 = c(0.016, 0.117),
       product_2 = prior_2*likelihood_2,
       posterior_2 = product_2/sum(product_2))
```

Уже на второй итерации, наша модель почти уверена, что это сообщение `spam`. На третьей итерации уверенность только растет:

```{r}
tibble(model = c("ham", "spam"),
       prior_3 = c(0.161, 0.839),
       likelihood_3 = c(0.016, 0.117),
       product_3 = prior_3*likelihood_3,
       posterior_3 = product_3/sum(product_3))
```

::: {.callout-note}
На основе первых трех слов посчитайте посчитайте вероятность гипотезы, что перед нами спамерское сообщение, если предположить, что каждое пятое сообщение -- спам. Ответ округлите до трех знаков после запятой.
:::

```{r}
#| echo: false

library(checkdown)
tibble(model = c("ham", "spam"),
       prior = c(0.8, 0.2),
       likelihood = c(0.135, 0.096),
       likelihood_2 = c(0.016, 0.117),
       product = prior*likelihood*likelihood_2*likelihood_2,
       posterior = product/sum(product)) |> 
  slice(2) |> 
  pull(posterior) |> 
  round(3) |> 
  check_question(placeholder = "0.123")
```

Из формулы Байеса следует, что не обязательно каждый раз делить на нормализующий делитель, это можно сделать единожды.

```{r}
tibble(model = c("ham", "spam"),
       prior = 0.5,
       likelihood = c(0.135, 0.096),
       likelihood_2 = c(0.016, 0.117),
       product = prior*likelihood*likelihood_2*likelihood_2,
       posterior = product/sum(product))
```

Из приведенных рассуждений также следует, что все равно в каком порядке мы производим байесовский апдейт: мы могли сначала умножить на значение правдоподобия для категории `NUM` и лишь в конце на значение правдоподобия `VERB`.

Также стоит отметить, что если данных много, то через какое-то время становится все равно, какое у нас было априорное распределение. Даже в нашем примере, в котором мы проанализировали первые три слова сообщения, модель, прогнозирующая, что сообщение спамерское, выиграет, даже если, согласно априорному распределению, спамерским является каждое 20 сообщение:

```{r}
tibble(model = c("ham", "spam"),
       prior = c(0.95, 0.05),
       likelihood = c(0.135, 0.096),
       likelihood_2 = c(0.016, 0.117),
       product = prior*likelihood*likelihood_2*likelihood_2,
       posterior = product/sum(product))
```

Самым главным отличием байесовского статистического вывода от фриквентистского, является то, что мы в результате получаем вероятность каждой из моделей. Это очень значительно отличается от фриквентистской практики нулевых гипотез и p-value, в соответствии с которыми мы можем лишь отвергнуть или не отвергнуть нулевую гипотезу.


::: {.callout-note}
Вашего друга похитили а на почту отправили [датасет](https://raw.githubusercontent.com/agricolamz/2024_HSE_b_da4l/main/data/weather.csv), в котором записаны данные о погоде из пяти городов. Ваш телефон зазвонил, и друг сказал, что не знает куда его похитили, но за окном легкий дождь (`Rain`). А в какой-то из следующих дней --- сильный дождь (`Rain, Thunderstorm`). Исходя из явно неверного предположения, что погодные условия каждый день не зависят друг от друга, сделайте байесовский апдейт и предположите, в какой город вероятнее всего похитили друга.
:::

```{r}
#| include: false

df <- read.csv("https://raw.githubusercontent.com/agricolamz/2024_HSE_b_da4l/main/data/weather.csv")
df |>
  count(city, events) |> 
  group_by(city) |> 
  mutate(prop = n/sum(n)) |> 
  ggplot(aes(city, prop, fill = events, label = round(prop, 3)))+
  geom_col()+
  geom_text(position = position_stack(vjust = 0.5), color = "white")

tibble(model = c("Auckland", "Beijing", "Chicago", "Mumbai", "San Diego"),
           prior_1 = 0.2,
           likelihood_1 = c(0.484, 0, 0.161, 0, 0.29),
           product_1 = prior_1*likelihood_1,
           posterior_1 = product_1/sum(product_1),
           likelihood_2 = c(0.032, 0, 0, 0, 0.065),
           product_2 = posterior_1*likelihood_2,
           posterior_2 = product_2/sum(product_2))
```

```{r}
#| echo: false

check_question(answer = "San Diego", options = c("Auckland", "Beijing", "Chicago", "Mumbai", "San Diego"))
```

::: {.callout-note}
Укажите получившуюся вероятность. Выполняя задание, округлите все вероятности и значения правдоподобия до 3 знаков после запятой.
:::

```{r}
#| echo: false

check_question(answer = 0.549)
```

## Разница между фриквентиским и байесовским подходами

![](images/gelman.png)

Картинка из одной из моих любимых книг по статистике [@efron16: 34].

## Биномиальные данные

Биномиальные данные возникают, когда нас интересует доля успехов в какой-то серии эксперементов Бернулли.

### Биномиальное распределение

Биномиальное распределение --- распределение количества успехов эксперементов Бернулли из *n* попыток с вероятностью успеха *p*.

$$P(k | n, p) = \frac{n!}{k!(n-k)!} \times p^k \times (1-p)^{n-k} =  {n \choose k} \times p^k \times (1-p)^{n-k}$$ 
$$ 0 \leq p \leq 1; n, k > 0$$

```{r}
tibble(x = 0:50,
           density = dbinom(x = x, size = 50, prob = 0.16)) |> 
  ggplot(aes(x, density))+
  geom_point()+
  geom_line()+
  labs(title = "Биномиальное распределение p = 0.16, n = 50")
```

### Бета распределение

$$P(x; α, β) = \frac{x^{α-1}\times (1-x)^{β-1}}{B(α, β)}; 0 \leq x \leq 1; α, β > 0$$

Бета функция:

$$Β(α, β) = \frac{Γ(α)\times Γ(β)}{Γ(α+β)} = \frac{(α-1)!(β-1)!}{(α+β-1)!} $$


```{r}
tibble(x = seq(0, 1, length.out = 100),
           density = dbeta(x = x, shape1 = 8, shape2 = 42)) |> 
  ggplot(aes(x, density))+
  geom_point()+
  geom_line()+
  labs(title = "Бета распределение α = 8, β = 42")
```

Можно поиграть с разными параметрами:

```{r}
#| eval: false

shiny::runGitHub("agricolamz/beta_distribution_shiny") 
```

$$\mu = \frac{\alpha}{\alpha+\beta}$$

$$\sigma^2 = \frac{\alpha\times\beta}{(\alpha+\beta)^2\times(\alpha+\beta+1)}$$


### Байесовский апдейт биномиальных данных

$$Beta_{post}(\alpha_{post}, \beta_{post}) = Beta(\alpha_{prior}+\alpha_{data}, \beta_{prior}+\beta_{data}),$$
где $Beta$ --- это бета распределение

```{r}
#| eval: false

shiny::runGitHub("agricolamz/bayes_for_binomial_app") 
```

::: {.callout-note}
Немного упрощая данные из статьи [@rosenbach03: 394], можно сказать что носители британского английского предпочитают *s*-генитив (90%) *of*-генитиву (10%). Проведите байесовский апдейт, если Вы наблюдаете в интервью британского актера из 120 контекстов 92 *s*-генитивов. Априорное распределение берите соразмерное данным. Ответ округлите до трёх или менее знаков после запятой.
:::


::: {.callout-note}
Параметр альфа:
:::

```{r}
#| echo: false

check_question(108+92)
```

::: {.callout-note}
Параметр бета:
:::

```{r}
#| echo: false

check_question(12+28)
```

### Байесовский апдейт биномиальных данных: несколько моделей


```{r}
tibble(x = rep(seq(0, 1, length.out = 100), 6),
           density = c(dbeta(unique(x), shape1 = 8, shape2 = 42),
                       dbeta(unique(x), shape1 = 16, shape2 = 34),
                       dbeta(unique(x), shape1 = 24, shape2 = 26),
                       dbeta(unique(x), shape1 = 8+4, shape2 = 42+16),
                       dbeta(unique(x), shape1 = 16+4, shape2 = 34+16),
                       dbeta(unique(x), shape1 = 24+4, shape2 = 26+16)),
           type = rep(c("prior", "prior", "prior", "posterior", "posterior", "posterior"), each = 100),
           dataset = rep(c("prior: 8, 42", "prior: 16, 34", "prior: 24, 26",
                           "prior: 8, 42", "prior: 16, 34", "prior: 24, 26"), each = 100)) |> 
  ggplot(aes(x, density, color = type))+
  geom_line()+
  facet_wrap(~dataset)+
  labs(title = "data = 4, 16")
```

### Что почитать?

Если остались неясности, то можно посмотреть 2-ую главу [@robinson17].

## Байесовский апдейт нормального распределения

Встроенный датасет `ChickWeight` содержит вес цыплят (`weight`) в зависимости от типа диеты (`Diet`). Мы будем анализировать 20-дневных птенцов.

```{r}
ChickWeight |> 
  filter(Time == 20) ->
  chicks

chicks |> 
  ggplot(aes(weight))+
  geom_density()
```

Начнем с апостериорных параметров для наблюдений $x_1, ... x_n$ со средним $\mu_{data}$ известной дисперсией $\sigma_{known}^2$


### Байесовский апдейт нормального распределения: выбор из нескольких моделей

Мы можем рассматривать эту задачу как выбор между несколькими моделями с разными средними:

```{r}
tibble(x = rep(1:400, 6),
           density = c(dnorm(unique(x), mean = 125, sd = 70),
                       dnorm(unique(x), mean = 150, sd = 70),
                       dnorm(unique(x), mean = 175, sd = 70),
                       dnorm(unique(x), mean = 200, sd = 70),
                       dnorm(unique(x), mean = 225, sd = 70),
                       dnorm(unique(x), mean = 250, sd = 70)),
           dataset = rep(1:6, each = 400)) |> 
  ggplot(aes(x, density, color = factor(dataset)))+
  geom_line()
```

Дальше мы можем точно так же апдейтить, как мы делали раньше:

```{r}
tibble(mu = seq(125, 250, by = 25),
           prior = 1/6,
           likelihood = c(prod(dnorm(chicks$weight, mean = 125, sd = 70)),
                          prod(dnorm(chicks$weight, mean = 150, sd = 70)),
                          prod(dnorm(chicks$weight, mean = 175, sd = 70)),
                          prod(dnorm(chicks$weight, mean = 200, sd = 70)),
                          prod(dnorm(chicks$weight, mean = 225, sd = 70)),
                          prod(dnorm(chicks$weight, mean = 250, sd = 70))),
           product = prior*likelihood,
           posterior = product/sum(product)) ->
  results
results
results |> 
  select(mu, prior, posterior) |> 
  pivot_longer(names_to = "type", values_to = "probability", prior:posterior) |> 
  ggplot(aes(mu, probability, color = type))+
  geom_point()+
  labs(title = "изменение вероятностей для каждой из моделей",
       x = "μ")
```

### Байесовский апдейт нормального распределения: непрерывный вариант

Во первых, нам понадобится некоторая мера, которая называется *точность* (precision):

$$\tau = \frac{1}{\sigma^2}$$

$$\tau_{post} = \tau_{prior} + \tau_{data} \Rightarrow \sigma^2_{post} = \frac{1}{\tau_{post}}$$


$$\mu_{post} = \frac{\mu_{prior} \times \tau_{prior} + \mu_{data} \times \tau_{data}}{\tau_{post}}$$

Так что если нашим априорным распределением мы назовем нормальное распределение со средним около 180 и стандартным отклонением 90, то процесс байесовского апдейта будет выглядеть вот так:

```{r}
sd_prior <- 90 
sd_data <- sd(chicks$weight)
sd_post <- 1/sqrt(1/sd_prior^2 + 1/sd_data^2)
mean_prior <- 180
mean_data <- mean(chicks$weight)
mean_post <- weighted.mean(c(mean_prior, mean_data), c(1/sd_prior^2, 1/sd_data^2))

chicks |> 
  ggplot(aes(weight)) +
  geom_histogram(aes(y = after_stat(density)))+
  stat_function(fun = dnorm, args = list(mean_prior,  sd_prior), color = "lightblue")+
  stat_function(fun = dnorm, args = list(mean_post,  sd_post), color = "red")
```

```{r}
#| eval: false

shiny::runGitHub("agricolamz/bayes_for_normal_app") 
```

::: {.callout-note}
В работе [@coretta2016] собраны [данные](https://raw.githubusercontent.com/agricolamz/2024_HSE_b_da4l/main/data/Coretta_2017_icelandic.csv) длительности исландских гласных. Отфильтруйте данные, произнесенные носителем `tt01` (переменная `speaker`), произведите байесовский апдейт данных, моделируя  длительность гласных (переменная `vowel.dur`) нормальным распределением и постройте график. В качестве априорного распределения используйте нормальное распределение со средним 87 и стандартным отклонением 25. 
:::

```{r}
#| echo: false

read_csv("https://raw.githubusercontent.com/agricolamz/2024_HSE_b_da4l/main/data/Coretta_2017_icelandic.csv") |> 
  filter(speaker == "tt01") ->
  vowels

sd_prior <- 25
sd_data <- sd(vowels$vowel.dur)
sd_post <- 1/sqrt(1/sd_prior^2 + 1/sd_data^2)
mean_prior <- 87
mean_data <- mean(vowels$vowel.dur)
mean_post <- weighted.mean(c(mean_prior, mean_data), c(1/sd_prior^2, 1/sd_data^2))

vowels |> 
  ggplot(aes(vowel.dur)) +
  geom_histogram(aes(y = after_stat(density)))+
  stat_function(fun = dnorm, args = list(mean_prior,  sd_prior), color = "lightblue")+
  stat_function(fun = dnorm, args = list(mean_post,  sd_post), color = "red")
```

### Что почитать?

* [Murphy K. P. (2007) Conjugate Bayesian analysis of the Gaussian distribution](https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf)
* [Jordan M. I. (2010) The Conjugate Prior for the Normal Distribution](https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture5.pdf)
* раздел 2.5 в Gelman A. et. al (2014) Bayesian Data Analysis

## Другие распределения

Мы обсудили биномиальные и нормальное распределенные данные. Так случилось, что для них есть короткий путь сделать байесовский апдейт, не применяя формулы Байеса. И нам так повезло, что связки априорного/апосториорного распределений и функции правдоподобия такие простые:

- априорного/апосториорного распределены как бета распределение, значит функция правдоподобия -- биномиальное распределение
- если мы моделируем данные при помощи нормального распределения, то все три распределения (априорное, функция правдопдобия и апосториорное) -- нормальные.

Такие отношения между распределениями называют сопряженными (conjugate). В результате для разных семейств функции правдоподобия существует список соответствующих сопряженных априорных распределений (conjugate prior), который можно найти, например, [здесь](https://en.wikipedia.org/wiki/Conjugate_prior).

В большинстве случаев используется (а на самом деле почти всегда) Марковские цепи Монте-Карло (MCMC).

## Вопросы к апостериорному распределению

> A frequentist uses impeccable logic to answer the wrong question, while a Bayesian answers the right question by making assumptions that nobody can fully believe in. (P. G. Hammer)

1) попытка оценить параметр θ и/или какой-нибудь интервал, в котором он лежит.
    * среднее апостериорного распределения (mean of the posterior estimation, MAP)
    * максимум апостериорного распределения (maximum a posteriori estimation, MAP)
    * байесовский доверительный интервал
2) ответить на вопросы вроде
    * какова вероятность, что значение θ больше некоторого значения $x$?
    * какова вероятность, что значение θ лежит в интервале $[x; y]$?
    * и т. п.
3) Выборки из апостериорного распределения (Posterior simulation):
    * симулируйте большую выборку из апостериорного распределения;
    * используйте полученную выборку для статистического вывода.
    
Допустим, мы получили апостериорное бета распределение с параметрами 20 и 70. Какова вероятность наблюдать значения больше 0.3?

```{r}
posterior_simulation <- rbeta(n = 10000, shape1 = 20, shape2 = 70)
sum(posterior_simulation > 0.3)/10000
```

И это не p-value! Это настоящие вероятности!
